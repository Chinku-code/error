    Medium:
    SizeLimit:  <unset>
  credential-socket:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  workload-certs:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  istio-envoy:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  istio-data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  istio-podinfo:
    Type:  DownwardAPI (a volume populated by information about the pod)
    Items:
      metadata.labels -> labels
      metadata.annotations -> annotations
  istio-token:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  43200
  istiod-ca-cert:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      istio-ca-root-cert
    Optional:  false
  kube-api-access-bwv5w:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
QoS Class:                   Burstable
Node-Selectors:              env=dev
Tolerations:                 node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason                 Age   From                                       Message
  ----    ------                 ----  ----                                       -------
  Normal  IPTablesUsageObserved  176m  openshift.io/iptables-deprecation-alerter  This pod appears to have created one or more iptables rules. IPTable
s is
deprecated and will no longer be available in RHEL 10 and later. You should
consider migrating to another API such as nftables or eBPF. See also
https://access.redhat.com/solutions/6739041

Example iptables rule seen in this pod:
-A PREROUTING -p tcp -j ISTIO_INBOUND
  Normal   Pulled   156m (x464 over 41h)   kubelet  Container image "image-registry.openshift-image-registry.svc:5000/dev-rns/spark-new@sha256:f92c4911e6769900060e9f6c38aed388354387082a7a36866ce959fadca67dce" already present ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ ^C
[osuser@bastion ~]$ clear
[osuser@bastion ~]$ oc get po
NAME                                     READY   STATUS             RESTARTS           AGE
ops-operationsservice-6cdf7fdc54-zmjgb   2/2     Running            0                  2d20h
refund-refundservice-59955c9988-rdx67    2/2     Running            0                  2d18h
sftp-sftpservice-64549474b9-lxs59        1/2     CrashLoopBackOff   11477 (3m2s ago)   40d
spark-new-6ddd7c9c5f-cmq25               1/2     CrashLoopBackOff   494 (4m32s ago)    41h
[osuser@bastion ~]$ oc logs -f spark-new-6ddd7c9c5f-cmq25
sh: line 1: spark-submit: command not found
[osuser@bastion ~]$ oc describe po spark-new-6ddd7c9c5f-cmq25
Name:             spark-new-6ddd7c9c5f-cmq25
Namespace:        dev-rns
Priority:         0
Service Account:  default
Node:             worker1.dev.sbiepay.sbi/10.177.142.141
Start Time:       Tue, 30 Dec 2025 13:24:21 +0000
Labels:           app=spark-new
                  deployment=spark-new
                  pod-template-hash=6ddd7c9c5f
                  security.istio.io/tlsMode=istio
                  service.istio.io/canonical-name=spark-new
                  service.istio.io/canonical-revision=latest
Annotations:      istio.io/rev: dev-istio
                  k8s.ovn.org/pod-networks:
                    {"default":{"ip_addresses":["172.16.9.89/23"],"mac_address":"0a:58:ac:10:09:59","gateway_ips":["172.16.8.1"],"routes":[{"dest":"172.16.0.0...
                  k8s.v1.cni.cncf.io/network-status:
                    [{
                        "name": "ovn-kubernetes",
                        "interface": "eth0",
                        "ips": [
                            "172.16.9.89"
                        ],
                        "mac": "0a:58:ac:10:09:59",
                        "default": true,
                        "dns": {}
                    }]
                  k8s.v1.cni.cncf.io/networks: default/istio-cni
                  kubectl.kubernetes.io/default-container: spark-new
                  kubectl.kubernetes.io/default-logs-container: spark-new
                  openshift.io/generated-by: OpenShiftWebConsole
                  openshift.io/scc: restricted-v2
                  prometheus.io/path: /stats/prometheus
                  prometheus.io/port: 15020
                  prometheus.io/scrape: true
                  seccomp.security.alpha.kubernetes.io/pod: runtime/default
                  sidecar.istio.io/interceptionMode: REDIRECT
                  sidecar.istio.io/status:
                    {"initContainers":["istio-validation"],"containers":["istio-proxy"],"volumes":["workload-socket","credential-socket","workload-certs","ist...
                  traffic.sidecar.istio.io/excludeInboundPorts: 15020
                  traffic.sidecar.istio.io/includeInboundPorts: *
                  traffic.sidecar.istio.io/includeOutboundIPRanges: *
Status:           Running
SeccompProfile:   RuntimeDefault
IP:               172.16.9.89
IPs:
  IP:           172.16.9.89
Controlled By:  ReplicaSet/spark-new-6ddd7c9c5f
Init Containers:
  istio-validation:
    Container ID:  cri-o://46634e5d017356c525754fc4bc62ed75a5b92df5084ed5af30834e73787bef8f
    Image:         registry.redhat.io/openshift-service-mesh/istio-proxyv2-rhel9@sha256:1306526a12590e284b1170cfccdf91388520360e2d7afab0d7f57111c4f28662
    Image ID:      registry.redhat.io/openshift-service-mesh/istio-proxyv2-rhel9@sha256:1306526a12590e284b1170cfccdf91388520360e2d7afab0d7f57111c4f28662
    Port:          <none>
    Host Port:     <none>
    Args:
      istio-iptables
      -p
      15001
      -z
      15006
      -u
      1001529999
      -m
      REDIRECT
      -i
      *
      -x

      -b
      *
      -d
      15090,15021,15020
      --log_output_level=default:info
      --run-validation
      --skip-rule-apply
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Tue, 30 Dec 2025 13:24:22 +0000
      Finished:     Tue, 30 Dec 2025 13:24:22 +0000
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     2
      memory:  1Gi
    Requests:
      cpu:        100m
      memory:     128Mi
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bwv5w (ro)
Containers:
  spark-new:
    Container ID:   cri-o://cb32450b75d41433783725ec2c6821810ff128c8b3c2a3748112a96411d14309
    Image:          image-registry.openshift-image-registry.svc:5000/dev-rns/spark-new@sha256:f92c4911e6769900060e9f6c38aed388354387082a7a36866ce959fadca67dce
    Image ID:       image-registry.openshift-image-registry.svc:5000/dev-rns/spark-new@sha256:f92c4911e6769900060e9f6c38aed388354387082a7a36866ce959fadca67dce
    Ports:          8080/TCP, 8443/TCP
    Host Ports:     0/TCP, 0/TCP
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    127
      Started:      Thu, 01 Jan 2026 07:08:27 +0000
      Finished:     Thu, 01 Jan 2026 07:08:27 +0000
    Ready:          False
    Restart Count:  494
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bwv5w (ro)
  istio-proxy:
    Container ID:  cri-o://3df0aa5eb0c74d1ea12ad9aec03b30c5405026f88b06da8120ccf55a29d10ef0
    Image:         registry.redhat.io/openshift-service-mesh/istio-proxyv2-rhel9@sha256:1306526a12590e284b1170cfccdf91388520360e2d7afab0d7f57111c4f28662
    Image ID:      registry.redhat.io/openshift-service-mesh/istio-proxyv2-rhel9@sha256:1306526a12590e284b1170cfccdf91388520360e2d7afab0d7f57111c4f28662
    Port:          15090/TCP
    Host Port:     0/TCP
    Args:
      proxy
      sidecar
      --domain
      $(POD_NAMESPACE).svc.cluster.local
      --proxyLogLevel=warning
      --proxyComponentLogLevel=misc:error
      --log_output_level=default:info
    State:          Running
      Started:      Tue, 30 Dec 2025 13:24:52 +0000
    Ready:          True
    Restart Count:  0
    Limits:
      cpu:     2
      memory:  1Gi
    Requests:
      cpu:      100m
      memory:   128Mi
    Readiness:  http-get http://:15021/healthz/ready delay=0s timeout=3s period=15s #success=1 #failure=4
    Startup:    http-get http://:15021/healthz/ready delay=0s timeout=3s period=1s #success=1 #failure=600
    Environment:
      PILOT_CERT_PROVIDER:           istiod
      CA_ADDR:                       istiod-dev-istio.dev-istio-system.svc:15012
      POD_NAME:                      spark-new-6ddd7c9c5f-cmq25 (v1:metadata.name)
      POD_NAMESPACE:                 dev-rns (v1:metadata.namespace)
      INSTANCE_IP:                    (v1:status.podIP)
      SERVICE_ACCOUNT:                (v1:spec.serviceAccountName)
      HOST_IP:                        (v1:status.hostIP)
      ISTIO_CPU_LIMIT:               2 (limits.cpu)
      PROXY_CONFIG:                  {"discoveryAddress":"istiod-dev-istio.dev-istio-system.svc:15012"}

      ISTIO_META_POD_PORTS:          [
                                         {"containerPort":8080,"protocol":"TCP"}
                                         ,{"containerPort":8443,"protocol":"TCP"}
                                     ]
      ISTIO_META_APP_CONTAINERS:     spark-new
      GOMEMLIMIT:                    1073741824 (limits.memory)
      GOMAXPROCS:                    2 (limits.cpu)
      ISTIO_META_CLUSTER_ID:         Kubernetes
      ISTIO_META_NODE_NAME:           (v1:spec.nodeName)
      ISTIO_META_INTERCEPTION_MODE:  REDIRECT
      ISTIO_META_WORKLOAD_NAME:      spark-new
      ISTIO_META_OWNER:              kubernetes://apis/apps/v1/namespaces/dev-rns/deployments/spark-new
      ISTIO_META_MESH_ID:            cluster.local
      TRUST_DOMAIN:                  cluster.local
    Mounts:
      /etc/istio/pod from istio-podinfo (rw)
      /etc/istio/proxy from istio-envoy (rw)
      /var/lib/istio/data from istio-data (rw)
      /var/run/secrets/credential-uds from credential-socket (rw)
      /var/run/secrets/istio from istiod-ca-cert (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bwv5w (ro)
      /var/run/secrets/tokens from istio-token (rw)
      /var/run/secrets/workload-spiffe-credentials from workload-certs (rw)
      /var/run/secrets/workload-spiffe-uds from workload-socket (rw)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  workload-socket:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  credential-socket:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  workload-certs:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  istio-envoy:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  istio-data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  istio-podinfo:
    Type:  DownwardAPI (a volume populated by information about the pod)
    Items:
      metadata.labels -> labels
      metadata.annotations -> annotations
  istio-token:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  43200
  istiod-ca-cert:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      istio-ca-root-cert
    Optional:  false
  kube-api-access-bwv5w:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
    ConfigMapName:           openshift-service-ca.crt
    ConfigMapOptional:       <nil>
QoS Class:                   Burstable
Node-Selectors:              env=dev
Tolerations:                 node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason                 Age   From                                       Message
  ----    ------                 ----  ----                                       -------
  Normal  IPTablesUsageObserved  178m  openshift.io/iptables-deprecation-alerter  This pod appears to have created one or more iptables rules. IPTables is
deprecated and will no longer be available in RHEL 10 and later. You should
consider migrating to another API such as nftables or eBPF. See also
https://access.redhat.com/solutions/6739041

Example iptables rule seen in this pod:
-A PREROUTING -p tcp -j ISTIO_INBOUND
  Normal   Pulled   158m (x464 over 41h)     kubelet  Container image "image-registry.openshift-image-registry.svc:5000/dev-rns/spark-new@sha256:f92c4911e6769900060e9f6c38aed388354387082a7a36866ce959fadca67dce" already present on machine
  Warning  BackOff  3m57s (x11530 over 41h)  kubelet  Back-off restarting failed container spark-new in pod spark-new-6ddd7c9c5f-cmq25_dev-rns(64e15acf-dffa-4ea2-9a1f-e302b47e8e89)


[osuser@bastion ~]$ oc logs -f spark-new-6ddd7c9c5f-cmq25
sh: line 1: spark-submit: command not found
[osuser@bastion ~]$





